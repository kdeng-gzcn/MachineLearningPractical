\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{icml2017}
\citation{Goodfellow-et-al-2016}
\citation{srivastava2014dropout}
\citation{Goodfellow-et-al-2016}
\citation{Goodfellow-et-al-2016}
\newlabel{sec:intro}{{1}{1}{}{section.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example_acccurves}{{1a}{1}{accuracy by epoch}{figure.caption.1}{}}
\newlabel{sub@fig:example_acccurves}{{a}{1}{accuracy by epoch}{figure.caption.1}{}}
\newlabel{fig:example_errorcurves}{{1b}{1}{error by epoch}{figure.caption.1}{}}
\newlabel{sub@fig:example_errorcurves}{{b}{1}{error by epoch}{figure.caption.1}{}}
\newlabel{fig:example}{{1}{1}{Training and validation curves in terms of classification accuracy (a) and cross-entropy error (b) on the EMNIST dataset for the baseline model}{figure.caption.1}{}}
\newlabel{sec:task1}{{2}{1}{}{section.2}{}}
\newlabel{tab:width_exp}{{1}{2}{Validation accuracy (\%) and training/validation error (in terms of cross-entropy error) for varying network widths on the EMNIST dataset}{table.caption.2}{}}
\newlabel{fig:width_acccurves}{{2a}{2}{accuracy by epoch}{figure.caption.3}{}}
\newlabel{sub@fig:width_acccurves}{{a}{2}{accuracy by epoch}{figure.caption.3}{}}
\newlabel{fig:width_errorcurves}{{2b}{2}{error by epoch}{figure.caption.3}{}}
\newlabel{sub@fig:width_errorcurves}{{b}{2}{error by epoch}{figure.caption.3}{}}
\newlabel{fig:width}{{2}{2}{Training and validation curves in terms of classification accuracy (a) and cross-entropy error (b) on the EMNIST dataset for different network widths}{figure.caption.3}{}}
\citation{srivastava2014dropout}
\newlabel{tab:depth_exps}{{2}{3}{Validation accuracy (\%) and training/validation error (in terms of cross-entropy error) for varying network depths on the EMNIST dataset}{table.caption.4}{}}
\newlabel{fig:depth_acccurves}{{3a}{3}{accuracy by epoch}{figure.caption.5}{}}
\newlabel{sub@fig:depth_acccurves}{{a}{3}{accuracy by epoch}{figure.caption.5}{}}
\newlabel{fig:depth_errorcurves}{{3b}{3}{error by epoch}{figure.caption.5}{}}
\newlabel{sub@fig:depth_errorcurves}{{b}{3}{error by epoch}{figure.caption.5}{}}
\newlabel{fig:depth}{{3}{3}{Training and validation curves in terms of classification accuracy (a) and cross-entropy error (b) on the EMNIST dataset for different network depths}{figure.caption.5}{}}
\newlabel{sec:task2.1}{{3}{3}{}{section.3}{}}
\citation{ng2004feature}
\newlabel{sec:task2.2}{{4}{4}{}{figure.caption.7}{}}
\bibdata{refs}
\bibcite{Goodfellow-et-al-2016}{{1}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{ng2004feature}{{2}{2004}{{Ng}}{{}}}
\bibcite{srivastava2014dropout}{{3}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\newlabel{tab:hp_search}{{3}{5}{Results of all hyperparameter search experiments. \emph {italics} indicate the best results per series (Dropout, L1 Regularisation, L2 Regularisation, Label smoothing) and \textbf {bold} indicates the best overall}{table.caption.6}{}}
\newlabel{sec:concl}{{5}{5}{}{section.5}{}}
\newlabel{fig:dropoutrates}{{4a}{6}{Accuracy and error by inclusion probability}{figure.caption.7}{}}
\newlabel{sub@fig:dropoutrates}{{a}{6}{Accuracy and error by inclusion probability}{figure.caption.7}{}}
\newlabel{fig:weightrates}{{4b}{6}{Accuracy and error by weight penalty}{figure.caption.7}{}}
\newlabel{sub@fig:weightrates}{{b}{6}{Accuracy and error by weight penalty}{figure.caption.7}{}}
\newlabel{fig:hp_search}{{4}{6}{Accuracy and error by regularisation strength of each method (Dropout and L1/L2 Regularisation)}{figure.caption.7}{}}
\gdef \@abspage@last{6}
