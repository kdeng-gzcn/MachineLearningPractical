\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{icml2017}
\citation{simonyan2014very,he2016deep}
\citation{glorot2010understanding}
\citation{bengio1993problem}
\citation{he2016deep}
\citation{glorot2010understanding}
\citation{glorot2010understanding}
\citation{bishop1995neural}
\citation{ioffe2015batch}
\citation{he2016deep,huang2017densely}
\citation{ioffe2015batch}
\citation{he2016deep}
\citation{rumelhart1986learning}
\newlabel{sec:intro}{{1}{1}{}{section.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:loss_curves}{{1a}{1}{Cross entropy error per epoch}{figure.caption.1}{}}
\newlabel{sub@fig:loss_curves}{{a}{1}{Cross entropy error per epoch}{figure.caption.1}{}}
\newlabel{fig:acc_curves}{{1b}{1}{Classification accuracy per epoch}{figure.caption.1}{}}
\newlabel{sub@fig:acc_curves}{{b}{1}{Classification accuracy per epoch}{figure.caption.1}{}}
\newlabel{fig:curves}{{1}{1}{Training curves for VGG08 and VGG38 in terms of (a) cross-entropy error and (b) classification accuracy}{figure.caption.1}{}}
\newlabel{sec:task1}{{2}{1}{}{section.2}{}}
\citation{bengio1993problem}
\citation{simonyan2014very}
\citation{ioffe2015batch}
\citation{lecun2012efficient}
\citation{santurkar2018does}
\newlabel{fig:grad_flow_08}{{2}{2}{Gradient flow on VGG08}{figure.caption.2}{}}
\newlabel{fig:avg_grad_flow_38}{{3}{2}{Gradient Flow on VGG38}{figure.caption.3}{}}
\newlabel{eq.fprop}{{1}{2}{}{equation.2.1}{}}
\newlabel{eq.bprop}{{2}{2}{}{equation.2.2}{}}
\newlabel{sec:lit_rev}{{3}{2}{}{section.3}{}}
\citation{he2016deep}
\citation{he2016deep}
\citation{he2016deep}
\citation{he2016deep,huang2017densely}
\citation{santurkar2018does}
\citation{ioffe2015batch}
\citation{he2016deep}
\citation{he2016deep}
\newlabel{eq.bnstats}{{3}{3}{}{equation.4.3}{}}
\newlabel{eq.bnop}{{5}{3}{}{equation.4.5}{}}
\citation{krizhevsky2009learning}
\citation{he2016deep}
\newlabel{fig:training_curves_bestModel}{{4}{4}{Training curves for VGG38 with Batch Normalisation and Residual Connection (Learning Rate 1e-2) in terms of cross-entropy error (left Y-axis) and classification accuracy (right Y-axis)}{figure.caption.4}{}}
\newlabel{fig:avg_grad_flow_bestModel}{{5}{4}{Gradient Flow on VGG38 with Batch Normalisation and Residual Connection (Learning Rate 1e-2)}{figure.caption.5}{}}
\newlabel{eq.grad_skip}{{6}{4}{}{equation.4.6}{}}
\newlabel{subsec:rescimp}{{5.1}{4}{}{subsection.5.1}{}}
\citation{he2016deep}
\citation{he2016deep}
\newlabel{tab:CIFAR_results}{{1}{5}{Experiment results (number of model parameters, Training and Validation loss and accuracy) for different combinations of VGG08, VGG38, Batch Normalisation (BN), and Residual Connections (RC), LR is learning rate}{table.caption.6}{}}
\newlabel{sec:disc}{{6}{5}{}{section.6}{}}
\newlabel{sec:concl}{{7}{5}{}{section.7}{}}
\bibdata{refs}
\bibcite{bengio1993problem}{{1}{1993}{{Bengio et~al.}}{{Bengio, Frasconi, and Simard}}}
\bibcite{bishop1995neural}{{2}{1995}{{Bishop et~al.}}{{}}}
\bibcite{glorot2010understanding}{{3}{2010}{{Glorot \& Bengio}}{{Glorot and Bengio}}}
\bibcite{he2016deep}{{4}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{huang2017densely}{{5}{2017}{{Huang et~al.}}{{Huang, Liu, Van Der~Maaten, and Weinberger}}}
\bibcite{ioffe2015batch}{{6}{2015}{{Ioffe \& Szegedy}}{{Ioffe and Szegedy}}}
\bibcite{krizhevsky2009learning}{{7}{2009}{{Krizhevsky et~al.}}{{Krizhevsky, Hinton, et~al.}}}
\bibcite{lecun2012efficient}{{8}{2012}{{LeCun et~al.}}{{LeCun, Bottou, Orr, and M{\"u}ller}}}
\bibcite{rumelhart1986learning}{{9}{1986}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{santurkar2018does}{{10}{2018}{{Santurkar et~al.}}{{Santurkar, Tsipras, Ilyas, and M{\k {a}}dry}}}
\bibcite{simonyan2014very}{{11}{2014}{{Simonyan \& Zisserman}}{{Simonyan and Zisserman}}}
\gdef \@abspage@last{6}
